{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to read a image\n",
    "# if image is png scale the image\n",
    "def read_image(img):\n",
    "    if img.endswith('png'):\n",
    "        return (mpimg.imread(img)*255).astype('uint8')\n",
    "    else:\n",
    "        return mpimg.imread(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to draw list of bounding boxes in image\n",
    "def draw_boxes(img, bboxes, color = (0, 0, 255), thick = 6):\n",
    "    img_copy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(img_copy, bbox[0], bbox[1], color, thick)\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize HOG Features generated by car image\n",
    "# The HOG feature will be input to the classifer\n",
    "test_img = read_image('./vehicles/KITTI_extracted/32.png')\n",
    "test_img_gray = cv2.cvtColor(test_img, cv2.COLOR_RGB2GRAY)\n",
    "features, hog_image = get_hog_features(test_img_gray, orient = 8, pix_per_cell = 8, cell_per_block = 2, vis=True)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax2.imshow(hog_image)\n",
    "ax2.set_title('HOG Image', fontsize=20)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a single image\n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    img_features = []\n",
    "    # Do Color Conversion\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)\n",
    "    \n",
    "    #Add Spatial Binning Features\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        img_features.append(spatial_features)\n",
    "    \n",
    "    #Add Histogram Features\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        img_features.append(hist_features)\n",
    "        \n",
    "    #Add HOG Features\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        img_features.append(hog_features)\n",
    "        \n",
    "    return np.concatenate(img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create features vector for list of images\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    features = []\n",
    "    for file in imgs:\n",
    "        image = read_image(file)\n",
    "        file_features = single_img_features(image, color_space, spatial_size, hist_bins, \n",
    "                                            orient, pix_per_cell, cell_per_block, \n",
    "                                            hog_channel, spatial_feat, hist_feat, hog_feat)\n",
    "        features.append(file_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read All the car and non-car images path\n",
    "cars = glob.glob('vehicles/**/*.png', recursive = True);\n",
    "notcars = glob.glob('non-vehicles/**/*.png', recursive = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total cars images are {0}'.format(len(cars)))\n",
    "print('Total non cars images are {0}'.format(len(notcars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paramters to be used to extract features\n",
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 8  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16,16) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Car Features\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Non Car Features\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate labels\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total training data is {0}\".format(len(X_train)))\n",
    "print(\"Total test data is {0}\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVC classifier and train it\n",
    "# Validate the performance on test data by calculating accuracy.\n",
    "import time\n",
    "svc = LinearSVC()\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to generate windows to be searched.\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "        \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    \n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    \n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    \n",
    "    window_list = []\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a list of windows and search for cars in those windows by creating feature vector for each window and using classier \n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    on_windows = []\n",
    "    for window in windows:\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        prediction = clf.predict(test_features)\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiscale sliding window search\n",
    "test_img = read_image('./cutouts/bbox-example-image.jpg')\n",
    "windows = [(64, 64), (128, 128), (192, 192)]\n",
    "overlap = [0.75, 0.7, 0.6]\n",
    "y_start_stop = [[450, 580], [350, 684], [350, 684]]\n",
    "\n",
    "windows_to_search = []\n",
    "for i in range(len(windows)):\n",
    "    temp = slide_window(test_img, y_start_stop=y_start_stop[i], xy_window=windows[i], xy_overlap=(overlap[i], overlap[i]))\n",
    "    windows_to_search.extend(temp)\n",
    "\n",
    "print('Total windows to search {0}'.format(len(windows_to_search)))\n",
    "\n",
    "positive_windows = search_windows(test_img, windows_to_search, \n",
    "                                  clf = svc, scaler = X_scaler, \n",
    "                                  color_space = color_space, \n",
    "                                  spatial_size = spatial_size, \n",
    "                                  hist_bins = hist_bins, \n",
    "                                  orient = orient, pix_per_cell = pix_per_cell, \n",
    "                                  cell_per_block = cell_per_block, hog_channel = hog_channel)\n",
    "\n",
    "img_with_search_windows = draw_boxes(test_img, windows_to_search)\n",
    "img_with_positive_windows = draw_boxes(test_img, positive_windows)\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax2.imshow(img_with_search_windows)\n",
    "ax2.set_title('Search Windows Image', fontsize=20)\n",
    "ax3.imshow(img_with_positive_windows)\n",
    "ax3.set_title('Positive Windows Image', fontsize=20)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to generate image with heat map\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    for box in bbox_list:\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Heatmap without threshold\n",
    "test_img_shape = test_img.shape\n",
    "heatmap = add_heat(np.zeros(test_img_shape), positive_windows)\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax2.imshow(img_with_positive_windows)\n",
    "ax2.set_title('Positive Windows Image', fontsize=20)\n",
    "ax3.imshow(heatmap)\n",
    "ax3.set_title('Heatmap Image', fontsize=20)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Heatmap with threshold\n",
    "test_img_shape = test_img.shape\n",
    "heatmap = add_heat(np.zeros(test_img_shape), positive_windows)\n",
    "threholded_heatmap = apply_threshold(heatmap, threshold = 2)\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax2.imshow(img_with_positive_windows)\n",
    "ax2.set_title('Positive Windows Image', fontsize=20)\n",
    "ax3.imshow(threholded_heatmap)\n",
    "ax3.set_title('Thresholded Heatmap Image', fontsize=20)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize after generating labels for threholded image\n",
    "from scipy.ndimage.measurements import label\n",
    "labels = label(threholded_heatmap)\n",
    "img_with_car = draw_labeled_bboxes(np.copy(test_img), labels)\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax2.imshow(img_with_positive_windows)\n",
    "ax2.set_title('Positive Windows Image', fontsize=20)\n",
    "ax3.imshow(img_with_car)\n",
    "ax3.set_title('Car Bounding Image', fontsize=20)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert from RGB to different color space\n",
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to find cars in image by using HOG subsampling\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "     \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    car_windows = []\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                car_windows.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))       \n",
    "    return car_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class that search for windows having cards using HOG subsampling function using different scales\n",
    "from scipy.ndimage.measurements import label\n",
    "class SearchCars:\n",
    "    def __init__(self, clf, X_scaler, \n",
    "                 color_space, spatial_size, \n",
    "                 hist_bins, orient, pix_per_cell, \n",
    "                 cell_per_block, hog_channel, \n",
    "                 spatial_feat, hist_feat, hog_feat):\n",
    "        self.clf = clf\n",
    "        self.X_scaler = X_scaler\n",
    "        self.color_space = color_space\n",
    "        self.spatial_size = spatial_size\n",
    "        self.hist_bins = hist_bins\n",
    "        self.orient = orient\n",
    "        self.pix_per_cell = pix_per_cell\n",
    "        self.cell_per_block = cell_per_block\n",
    "        self.hog_channel = hog_channel\n",
    "        self.spatial_feat = spatial_feat\n",
    "        self.hist_feat = hist_feat\n",
    "        self.hog_feat = hog_feat\n",
    "        \n",
    "        \n",
    "    def find_hot_windows(self, img):\n",
    "        ystart = [350, 380, 380]\n",
    "        ystop =  [656, 712, 712]\n",
    "        scale =  [1.0, 1.5, 2.0]\n",
    "        \n",
    "        hot_windows = []\n",
    "        for i in range(len(scale)):\n",
    "            car_windows = find_cars(img, ystart[i], ystop[i], scale[i], \n",
    "                                self.clf, self.X_scaler, \n",
    "                                self.orient, self.pix_per_cell, \n",
    "                                self.cell_per_block, self.spatial_size, self.hist_bins)\n",
    "            hot_windows.extend(car_windows)\n",
    "        return hot_windows\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_cars = SearchCars(svc, X_scaler, color_space, \n",
    "                         spatial_size, hist_bins, orient,\n",
    "                         pix_per_cell, cell_per_block, \n",
    "                         hog_channel, spatial_feat, \n",
    "                         hist_feat, hog_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img = read_image('cutouts/bbox-example-image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_windows = search_cars.find_hot_windows(test_img)\n",
    "draw_img = draw_boxes(test_img, hot_windows)\n",
    "plt.imshow(draw_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from functools import reduce\n",
    "\n",
    "class HeatHistory():\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "def processVideo(inputVideo, outputVideo, frames_to_remember=5, threshhold=1):\n",
    "    \"\"\"\n",
    "    Process the video `inputVideo` to find the cars and saves the video to `outputVideo`.\n",
    "    \"\"\"\n",
    "    history = HeatHistory()\n",
    "\n",
    "    def pipeline(img):\n",
    "        boxes = search_cars.find_hot_windows(img)\n",
    "        img_shape = img.shape\n",
    "        heatmap = add_heat(np.zeros(img_shape), boxes)\n",
    "        if len(history.history) >= frames_to_remember:\n",
    "            history.history = history.history[1:]\n",
    "\n",
    "        history.history.append(heatmap)\n",
    "        heat_history = reduce(lambda h, acc: h + acc, history.history)/frames_to_remember\n",
    "        heatmap = apply_threshold(heat_history, threshhold)\n",
    "        labels = label(heatmap)\n",
    "\n",
    "        return draw_labeled_bboxes(np.copy(img), labels)\n",
    "\n",
    "    myclip = VideoFileClip(inputVideo)\n",
    "    output_video = myclip.fl_image(pipeline)\n",
    "    output_video.write_videofile(outputVideo, audio=False)\n",
    "    \n",
    "processVideo('./project_video.mp4', './output_project_video.mp4', threshhold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_project_video.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
